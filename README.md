<p align="center"><h1>IPEX-LLM Tutorial</h1><p>
  
<h4 align="center">
    <p>
        <b>English</b> |
        <a href="./Chinese_Version/README.md">中文</a>
    <p>
</h4>

[_IPEX-LLM_](https://github.com/intel-analytics/ipex-llm/tree/main/python/llm) is a low-bit LLM library on Intel XPU (Xeon/Core/Flex/Arc/PVC). This repository contains tutorials to help you understand what is _IPEX-LLM_ and how to use _IPEX-LLM_ to build LLM applications.

The tutorials are organized as follows:
- [Chapter 1 **`Introduction`**](./ch_1_Introduction/) introduces what is _IPEX-LLM_ and what you can do with it. 
- [Chapter 2 **`Environment Setup`**](./ch_2_Environment_Setup/) provides a set of best practices for setting-up your environment.
- [Chapter 3 **`Application Development: Basics`**](./ch_3_AppDev_Basic/) introduces the basic usage of _IPEX-LLM_ and how to build a very simple Chat application.
- [Chapter 4 **`Chinese Support`**](./ch_4_Chinese_Support/) shows the usage of some LLMs which suppports Chinese input/output, e.g. ChatGLM2, Baichuan  
- [Chapter 5 **`Application Development: Intermediate`**](./ch_5_AppDev_Intermediate/) introduces intermediate-level knowledge for application development using _IPEX-LLM_, e.g. How to build a more sophisticated Chatbot, Speech recoginition, etc. 
- [Chapter 6 **`GPU Acceleration`**](./ch_6_GPU_Acceleration/) introduces how to use Intel GPU to accelerate LLMs using _IPEX-LLM_.
- [Chapter 7 **`Finetune`**](./ch_7_Finetune/) introduces how to do Finetune using _IPEX-LLM_.
- [Chapter 8 **`Application Development: Advanced`**](./ch_8_AppDev_Advanced/) introduces advanced-level knowledge for application development using _IPEX-LLM_, e.g. langchain usage. 

[^1]: Performance varies by use, configuration and other factors. `ipex-llm` may not optimize to the same degree for non-Intel products. Learn more at www.Intel.com/PerformanceIndex.
